# Student Success Predictor

Predicts whether a student will **Pass** or **Fail** using classic machine learning on simple academic & lifestyle signals.

## ğŸ” What it does
- Trains a **Logistic Regression** model to classify student outcome (Pass/Fail).
- Uses features: **StudyHours, Attendance, PastScore, SleepHours, Internet** (Yes/No).
- Shows evaluation via **classification report** and **confusion matrix**.

## ğŸ“‚ Recommended Repo Structure
```
student-success-predictor/
â”œâ”€ data/
â”‚  â””â”€ student_success_dataset.csv
â”œâ”€ notebooks/
â”‚  â””â”€ Student_Success_Predictor.ipynb
â”œâ”€ src/
â”‚  â””â”€ train.py
â”œâ”€ models/              # saved models (created after training)
â”œâ”€ reports/             # metrics & plots (auto-created)
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ LICENSE
```

## ğŸ§° Tech Stack
Python, pandas, numpy, scikit-learn, matplotlib, seaborn, Jupyter Notebook

## ğŸš€ Quickstart
1) **Clone the repo**
```bash
git clone https://github.com/<username>/<repo-name>.git
cd <repo-name>
```

2) **Create folders**
```bash
mkdir -p data notebooks src models reports
```

3) **Add your files**
- Put your dataset at: `data/student_success_dataset.csv`
- Put your notebook at: `notebooks/Student_Success_Predictor.ipynb`

4) **Install deps**
```bash
pip install -r requirements.txt
```

5) **Train from script (optional, in addition to the notebook)**
```bash
python src/train.py --data data/student_success_dataset.csv --outdir .
```

This will:
- Train a Logistic Regression pipeline
- Save model to `models/logreg.pkl`
- Save metrics to `reports/metrics.txt`
- Save confusion matrix plot to `reports/confusion_matrix.png`

## ğŸ§ª Features (columns)
- `Internet` â€“ Yes/No (encoded)
- `StudyHours` â€“ avg study hours/day
- `Attendance` â€“ percentage (0â€“100)
- `PastScore` â€“ previous exam score
- `SleepHours` â€“ avg sleep hours/day
- **Target:** `Passed` â€“ Yes/No (encoded)

## ğŸ“ˆ Example Outputs
- **Classification report** (precision/recall/F1)
- **Confusion matrix** image

> Note: Actual scores depend on your dataset.

## ğŸ›£ï¸ Roadmap / Ideas
- Try other models (Random Forest, SVM, XGBoost)
- Cross-validation & hyperparameter tuning
- Feature importance & SHAP explanations
- Simple web app (Flask/Streamlit) for live predictions

## ğŸ“œ License
MIT â€” see `LICENSE` for details.

## ğŸ™Œ Acknowledgements
Made by Utkarsh Singh.
